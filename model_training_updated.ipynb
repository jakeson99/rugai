{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torcheval.metrics import MulticlassAccuracy\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the transform to resize the images\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# get labels from folder names\n",
    "dataset = datasets.ImageFolder(root=\"data\", transform=transform)\n",
    "\n",
    "# create random train test split from data\n",
    "rand_generator = torch.Generator().manual_seed(42)\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset, [0.8, 0.1, 0.1], generator=rand_generator\n",
    ")\n",
    "print(f\"{len(train_dataset)} training images\")\n",
    "print(f\"{len(val_dataset)} validation images\")\n",
    "print(f\"{len(test_dataset)} testing images\")\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the encoding for each class label\n",
    "class_to_idx = dataset.class_to_idx\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "print(idx_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert tensor to numpy and plot as image\n",
    "def imshow(image, ax=None, title=None) -> None:\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    # unnormalize the image\n",
    "    image = image / 2 + 0.5\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "    ax.imshow(image)\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "\n",
    "# plot training images\n",
    "images, labels = next(iter(train_dataloader))\n",
    "fig, axes = plt.subplots(1, 10, figsize=(25, 25))\n",
    "for i in range(10):\n",
    "    class_name = idx_to_class[int(labels[i])]\n",
    "    imshow(images[i], ax=axes[i], title=class_name)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot validation images\n",
    "images, labels = next(iter(val_dataloader))\n",
    "fig, axes = plt.subplots(1, 10, figsize=(25, 25))\n",
    "for i in range(10):\n",
    "    class_name = idx_to_class[int(labels[i])]\n",
    "    imshow(images[i], ax=axes[i], title=class_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot test images\n",
    "images, labels = next(iter(test_dataloader))\n",
    "fig, axes = plt.subplots(1, 10, figsize=(25, 25))\n",
    "for i in range(10):\n",
    "    class_name = idx_to_class[int(labels[i])]\n",
    "    imshow(images[i], ax=axes[i], title=class_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Initialize a Counter to count instances\n",
    "label_counts = Counter()\n",
    "\n",
    "# Loop over the DataLoader to get the labels\n",
    "for _, labels in train_dataloader:\n",
    "    label_counts.update(labels.tolist())\n",
    "\n",
    "# Convert the dataset class indices to class names\n",
    "class_to_idx = dataset.class_to_idx\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "\n",
    "# Print the counts for each class\n",
    "print(f\"Train dataset has:\")\n",
    "for label, count in label_counts.items():\n",
    "    class_name = idx_to_class[label]\n",
    "    print(f\"Class {class_name} has {count} instances\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Counter to count instances\n",
    "label_counts = Counter()\n",
    "\n",
    "# Loop over the DataLoader to get the labels\n",
    "for _, labels in val_dataloader:\n",
    "    label_counts.update(labels.tolist())\n",
    "\n",
    "# Convert the dataset class indices to class names\n",
    "class_to_idx = dataset.class_to_idx\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "\n",
    "# Print the counts for each class\n",
    "print(f\"Validaiton dataset has:\")\n",
    "for label, count in label_counts.items():\n",
    "    class_name = idx_to_class[label]\n",
    "    print(f\"Class {class_name} has {count} instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Initialize a Counter to count instances\n",
    "label_counts = Counter()\n",
    "\n",
    "# Loop over the DataLoader to get the labels\n",
    "for _, labels in test_dataloader:\n",
    "    label_counts.update(labels.tolist())\n",
    "\n",
    "# Convert the dataset class indices to class names\n",
    "class_to_idx = dataset.class_to_idx\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "\n",
    "# Print the counts for each class\n",
    "print(f\"Test dataset has:\")\n",
    "for label, count in label_counts.items():\n",
    "    class_name = idx_to_class[label]\n",
    "    print(f\"Class {class_name} has {count} instances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetworkWithDropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.fc1 = nn.Linear(128 * 28 * 28, 512)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, len(dataset.class_to_idx))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "\n",
    "model = NeuralNetworkWithDropout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer, loss and accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement focal loss to address the class imbalance\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Implement focal loss to address the class imbalance in the data. Focal loss\n",
    "    will adjust the loss by giving a higher weight to samples with lower probability\n",
    "    of being correctly classified.\n",
    "\n",
    "    https://arxiv.org/pdf/1708.02002\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=1, gamma=2, reduction=\"mean\"):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.name = \"Focal Loss\"\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = F.cross_entropy(inputs, targets, reduction=\"none\")\n",
    "        # prevent NaNs when probability is 0 by computing probability of true class\n",
    "        prob_true = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1 - prob_true) ** self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduction == \"none\":\n",
    "            pass\n",
    "        elif self.reduction == \"mean\":\n",
    "            return torch.mean(F_loss)\n",
    "        elif self.reduction == \"sum\":\n",
    "            return torch.sum(F_loss)\n",
    "        else:\n",
    "            msg = f\"An invalid value was selected for arg 'reduction': {self.reduction} \\n Supported reduction values: 'none', 'mean', 'sum'\"\n",
    "            raise ValueError(msg)\n",
    "\n",
    "\n",
    "focal_loss = FocalLoss(alpha=0.25, gamma=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.02\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = focal_loss\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_fn_params(loss_fn):\n",
    "    # Extract alpha, gamma, and reduction parameters from the loss function, if available\n",
    "    params = {}\n",
    "    for attr in [\"alpha\", \"gamma\", \"reduction\"]:\n",
    "        if hasattr(loss_fn, attr):\n",
    "            params[attr] = getattr(loss_fn, attr)\n",
    "    return params\n",
    "\n",
    "\n",
    "def initialize_wandb(model, train_dataloader, learning_rate, epochs, loss_fn, patience):\n",
    "    config = {\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"architecture\": model.__class__.__name__,\n",
    "        \"dataset\": \"rugs\",\n",
    "        \"epochs\": epochs,\n",
    "        \"batch_size\": train_dataloader.batch_size,\n",
    "        \"loss_function\": loss_fn.__class__.__name__,\n",
    "        \"patience\": patience,\n",
    "    }\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            config[name] = {\n",
    "                \"in_channels\"\n",
    "                if isinstance(module, nn.Conv2d)\n",
    "                else \"in_features\": module.in_channels\n",
    "                if isinstance(module, nn.Conv2d)\n",
    "                else module.in_features,\n",
    "                \"out_channels\"\n",
    "                if isinstance(module, nn.Conv2d)\n",
    "                else \"out_features\": module.out_channels\n",
    "                if isinstance(module, nn.Conv2d)\n",
    "                else module.out_features,\n",
    "            }\n",
    "        if isinstance(module, nn.Dropout):\n",
    "            config[f\"{name}_dropout_rate\"] = module.p\n",
    "\n",
    "    loss_fn_params = get_loss_fn_params(loss_fn)\n",
    "    config.update(loss_fn_params)\n",
    "\n",
    "    wandb.init(\n",
    "        project=\"rugai\",\n",
    "        config=config,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    num_epochs,\n",
    "    device,\n",
    "    num_classes,\n",
    "    model_name,\n",
    "    checkpoint_dir,\n",
    "    early_stopping_patience=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Training loop with wandb integration and MulticlassAccuracy metric\n",
    "\n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        train_loader: Training data loader\n",
    "        val_loader: Validation data loader\n",
    "        criterion: Loss function\n",
    "        optimizer: Optimizer\n",
    "        num_epochs: Maximum number of epochs\n",
    "        device: Device to train on ('cuda' or 'cpu')\n",
    "        project_name: WandB project name\n",
    "        model_name: Name for saving model checkpoints\n",
    "        num_classes: Number of classes for accuracy metric\n",
    "        save_every: Save model every N epochs\n",
    "        early_stopping_patience: Number of epochs to wait before early stopping\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize wandb\n",
    "    initialize_wandb(\n",
    "        model,\n",
    "        train_loader,\n",
    "        learning_rate,\n",
    "        num_epochs,\n",
    "        criterion,\n",
    "        early_stopping_patience,\n",
    "    )\n",
    "\n",
    "    print(f\"Using {device} device\")\n",
    "\n",
    "    # Log model architecture\n",
    "    wandb.watch(model)\n",
    "\n",
    "    # Initialize accuracy metrics\n",
    "    train_accuracy = MulticlassAccuracy(num_classes=num_classes).to(device)\n",
    "    val_accuracy = MulticlassAccuracy(num_classes=num_classes).to(device)\n",
    "\n",
    "    # Move model to device\n",
    "    model = model.to(device)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "\n",
    "    # paths for saving models\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    best_model_path = os.path.join(checkpoint_dir, f\"{model_name}_{timestamp}_best.pt\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "\n",
    "        train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
    "        for batch_idx, (data, target) in enumerate(train_bar):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update metrics\n",
    "            train_loss += loss.item()\n",
    "            # Update accuracy metric (accumulates automatically)\n",
    "            train_accuracy.update(output, target)\n",
    "\n",
    "            # Get current accuracy for progress bar\n",
    "            current_train_acc = train_accuracy.compute()\n",
    "\n",
    "            # Update progress bar\n",
    "            train_bar.set_postfix(\n",
    "                {\n",
    "                    \"loss\": f\"{train_loss/(batch_idx+1):.4f}\",\n",
    "                    \"acc\": f\"{100.*current_train_acc:.2f}%\",\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Get final training accuracy for the epoch\n",
    "        final_train_acc = train_accuracy.compute()\n",
    "        # Reset training accuracy for next epoch\n",
    "        train_accuracy.reset()\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\")\n",
    "            for batch_idx, (data, target) in enumerate(val_bar):\n",
    "                data, target = data.to(device), target.to(device)\n",
    "\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "\n",
    "                # Update metrics\n",
    "                val_loss += loss.item()\n",
    "                # Update accuracy metric (accumulates automatically)\n",
    "                val_accuracy.update(output, target)\n",
    "\n",
    "                # Get current accuracy for progress bar\n",
    "                current_val_acc = val_accuracy.compute()\n",
    "\n",
    "                # Update progress bar\n",
    "                val_bar.set_postfix(\n",
    "                    {\n",
    "                        \"loss\": f\"{val_loss/(batch_idx+1):.4f}\",\n",
    "                        \"acc\": f\"{100.*current_val_acc:.2f}%\",\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        # Get final validation accuracy for the epoch\n",
    "        final_val_acc = val_accuracy.compute()\n",
    "        # Reset validation accuracy for next epoch\n",
    "        val_accuracy.reset()\n",
    "\n",
    "        # Calculate epoch metrics\n",
    "        epoch_train_loss = train_loss / len(train_loader)\n",
    "        epoch_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        # Log metrics to wandb\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"train_loss\": epoch_train_loss,\n",
    "                \"train_acc\": final_train_acc * 100,\n",
    "                \"val_loss\": epoch_val_loss,\n",
    "                \"val_acc\": final_val_acc * 100,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            best_val_acc = final_val_acc\n",
    "            patience_counter = 0\n",
    "\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"model_state_dict\": model.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    \"train_loss\": epoch_train_loss,\n",
    "                    \"val_loss\": epoch_val_loss,\n",
    "                    \"val_acc\": final_val_acc,\n",
    "                    \"best_val_loss\": best_val_loss,\n",
    "                    \"best_val_acc\": best_val_acc,\n",
    "                },\n",
    "                best_model_path,\n",
    "            )\n",
    "\n",
    "            # Log model checkpoint to wandb\n",
    "            wandb.save(best_model_path)\n",
    "\n",
    "            print(\n",
    "                f\"Epoch {epoch + 1}: New best model saved to {best_model_path} with val_loss: {best_val_loss:.4f}, val_acc: {best_val_acc:.4f}\"\n",
    "            )\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        # Early stopping\n",
    "        if early_stopping_patience and patience_counter >= early_stopping_patience:\n",
    "            print(f\"Early stopping triggered after {epoch + 1} epochs\")\n",
    "            break\n",
    "\n",
    "    wandb.finish()\n",
    "    return model\n",
    "\n",
    "# Train the model\n",
    "trained_model = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_dataloader,\n",
    "    val_loader=val_dataloader,\n",
    "    criterion=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=2,\n",
    "    device=torch.device(\n",
    "        \"cuda\"\n",
    "        if torch.cuda.is_available()\n",
    "        else \"mps\"\n",
    "        if torch.backends.mps.is_available()\n",
    "        else \"cpu\"\n",
    "    ),\n",
    "    num_classes=len(class_to_idx),\n",
    "    model_name=model.__class__.__name__,\n",
    "    checkpoint_dir=\"model/ckpt\",\n",
    "    early_stopping_patience=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming class_to_idx is already defined\n",
    "class_to_idx = dataset.class_to_idx\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Retrieve a single image and label from the test dataloader\n",
    "images, labels = next(iter(test_dataloader))\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "# Make a prediction\n",
    "with torch.no_grad():\n",
    "    outputs = model(images)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "# Print the predicted label for the first image\n",
    "image = images[0]\n",
    "predicted_label = preds[0].item()\n",
    "true_label = labels[0].item()\n",
    "\n",
    "print(f\"Predicted: {idx_to_class[predicted_label]}, True: {idx_to_class[true_label]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on single image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming class_to_idx and your model are already defined\n",
    "class_to_idx = dataset.class_to_idx\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "\n",
    "\n",
    "# Load an arbitrary image\n",
    "def load_image(image_path):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "    image = Image.open(image_path)\n",
    "    image = transform(image).unsqueeze(0)  # Add a batch dimension\n",
    "    return image\n",
    "\n",
    "\n",
    "# Predict the class for the given image\n",
    "def predict_image_class(image_path, model):\n",
    "    image = load_image(image_path).to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        predicted_class = predicted.item()\n",
    "        class_name = idx_to_class[predicted_class]\n",
    "        return class_name\n",
    "\n",
    "\n",
    "# Example usage\n",
    "image_path = \"predict/IMG_2341.jpg\"\n",
    "predicted_class_name = predict_image_class(image_path, model)\n",
    "print(f\"The predicted class for the image is: {predicted_class_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of Test Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(all_preds, all_labels, num_classes, device=\"mps\"):\n",
    "    \"\"\"\n",
    "    Evaluate model predictions using MulticlassAccuracy\n",
    "\n",
    "    Args:\n",
    "        all_preds: Predictions array/tensor (numpy array or torch tensor)\n",
    "        all_labels: Ground truth labels array/tensor (numpy array or torch tensor)\n",
    "        num_classes: Number of classes in the dataset\n",
    "        device: Device to compute accuracy on ('cuda' or 'cpu')\n",
    "\n",
    "    Returns:\n",
    "        float: Accuracy score\n",
    "    \"\"\"\n",
    "    # Convert numpy arrays to torch tensors if necessary\n",
    "    if isinstance(all_preds, np.ndarray):\n",
    "        all_preds = torch.from_numpy(all_preds)\n",
    "    if isinstance(all_labels, np.ndarray):\n",
    "        all_labels = torch.from_numpy(all_labels)\n",
    "\n",
    "    # Ensure tensors are of type Long/int64\n",
    "    all_preds = all_preds.long()\n",
    "    all_labels = all_labels.long()\n",
    "\n",
    "    # Move tensors to specified device\n",
    "    all_preds = all_preds.to(device)\n",
    "    all_labels = all_labels.to(device)\n",
    "\n",
    "    # Initialize and compute accuracy\n",
    "    accuracy = MulticlassAccuracy(num_classes=num_classes).to(device)\n",
    "    accuracy.update(all_preds, all_labels)\n",
    "    return accuracy.compute().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    return all_preds, all_labels\n",
    "\n",
    "\n",
    "# Generate predictions\n",
    "all_preds, all_labels = get_predictions(model, test_dataloader, device)\n",
    "\n",
    "# Calculate precision, recall, and f1 scores\n",
    "precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
    "recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
    "f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "accuracy = evaluate_model(all_preds, all_labels, len(idx_to_class), device)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# create confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Calculate False Positive Rate for each class\n",
    "FP = cm.sum(axis=0) - np.diag(cm)\n",
    "FN = cm.sum(axis=1) - np.diag(cm)\n",
    "TP = np.diag(cm)\n",
    "TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "# False Positive Rate: FP / (FP + TN)\n",
    "FPR = FP / (FP + TN)\n",
    "\n",
    "# Recall: TP / (TP + FN)\n",
    "Recall = TP / (TP + FN)\n",
    "\n",
    "for i, fpr in enumerate(FPR):\n",
    "    class_name = list(class_to_idx.keys())[i]\n",
    "    print(f\"Class {class_name} - FPR: {FPR[i]:.4f}, Recall: {Recall[i]:.4f}\")\n",
    "\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm, display_labels=list(class_to_idx.keys())\n",
    ")\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "disp.plot(cmap=plt.cm.Blues, ax=ax)\n",
    "plt.title(\"Confusion Matrix (Absolute values)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm_normalized, display_labels=list(class_to_idx.keys())\n",
    ")\n",
    "disp.plot(cmap=plt.cm.Blues, ax=ax, values_format=\".2f\")\n",
    "plt.title(\"Confusion Matrix (Proportion)\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rugai-0fpEKXoe-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
